{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-29T00:04:49.913547Z",
     "iopub.status.busy": "2023-07-29T00:04:49.913144Z",
     "iopub.status.idle": "2023-07-29T00:04:49.919554Z",
     "shell.execute_reply": "2023-07-29T00:04:49.918351Z",
     "shell.execute_reply.started": "2023-07-29T00:04:49.913515Z"
    }
   },
   "outputs": [],
   "source": [
    "#keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten,Conv1D, MaxPool1D,LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-macosx_11_0_arm64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./miniconda3/lib/python3.10/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in ./miniconda3/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.12.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:39:56.553909Z",
     "iopub.status.busy": "2023-07-28T22:39:56.553509Z",
     "iopub.status.idle": "2023-07-28T22:39:56.559678Z",
     "shell.execute_reply": "2023-07-28T22:39:56.558520Z",
     "shell.execute_reply.started": "2023-07-28T22:39:56.553873Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-macosx_12_0_arm64.whl (1.9 kB)\n",
      "Collecting tensorflow-macos==2.13.0\n",
      "  Downloading tensorflow_macos-2.13.0-cp310-cp310-macosx_12_0_arm64.whl (189.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.9.0-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in ./miniconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: setuptools in ./miniconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (65.6.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.56.2-cp310-cp310-macosx_12_0_universal2.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in ./miniconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./miniconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-macosx_11_0_arm64.whl (36 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in ./miniconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./miniconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./miniconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.28.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in ./miniconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.14)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./miniconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, markdown, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.2 h5py-3.9.0 libclang-16.0.6 markdown-3.4.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-macos-2.13.0 termcolor-2.3.0 werkzeug-2.3.6 wrapt-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:52:22.419149Z",
     "iopub.status.busy": "2023-07-28T22:52:22.418599Z",
     "iopub.status.idle": "2023-07-28T22:54:24.067016Z",
     "shell.execute_reply": "2023-07-28T22:54:24.065751Z",
     "shell.execute_reply.started": "2023-07-28T22:52:22.419104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp310-cp310-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.11.1-cp310-cp310-macosx_12_0_arm64.whl (29.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.6/29.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in ./miniconda3/lib/python3.10/site-packages (from gensim) (1.24.3)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "Successfully installed gensim-4.3.1 scipy-1.11.1 smart-open-6.3.0\n",
      "Collecting keras\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.13.1\n",
      "Requirement already satisfied: pandas in ./miniconda3/lib/python3.10/site-packages (2.0.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tzdata>=2022.1 in ./miniconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./miniconda3/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.2\n",
      "    Uninstalling pandas-2.0.2:\n",
      "      Successfully uninstalled pandas-2.0.2\n",
      "Successfully installed pandas-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:54:27.327621Z",
     "iopub.status.busy": "2023-07-28T22:54:27.326975Z",
     "iopub.status.idle": "2023-07-28T22:54:27.332892Z",
     "shell.execute_reply": "2023-07-28T22:54:27.331802Z",
     "shell.execute_reply.started": "2023-07-28T22:54:27.327585Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in ./miniconda3/lib/python3.10/site-packages (0.0.post7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:40:41.570928Z",
     "iopub.status.busy": "2023-07-28T22:40:41.570542Z",
     "iopub.status.idle": "2023-07-28T22:40:41.576870Z",
     "shell.execute_reply": "2023-07-28T22:40:41.575689Z",
     "shell.execute_reply.started": "2023-07-28T22:40:41.570898Z"
    }
   },
   "outputs": [],
   "source": [
    "#nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "#wrod2vec\n",
    "import gensim\n",
    "\n",
    "#utility\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-macosx_12_0_arm64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in ./miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:40:42.118280Z",
     "iopub.status.busy": "2023-07-28T22:40:42.117886Z",
     "iopub.status.idle": "2023-07-28T22:40:42.125677Z",
     "shell.execute_reply": "2023-07-28T22:40:42.124357Z",
     "shell.execute_reply.started": "2023-07-28T22:40:42.118250Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Set log\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mlogging\u001b[49m\u001b[38;5;241m.\u001b[39mbasicConfig(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "#Dataframe\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:14:44.839249Z",
     "iopub.status.busy": "2023-07-28T23:14:44.838182Z",
     "iopub.status.idle": "2023-07-28T23:14:44.843276Z",
     "shell.execute_reply": "2023-07-28T23:14:44.842521Z",
     "shell.execute_reply.started": "2023-07-28T23:14:44.839209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set log\n",
    "# This line sets up logging configuration for displaying messages in a specific format.\n",
    "# It will print the timestamp, log level, and the message itself.\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:40:50.516505Z",
     "iopub.status.busy": "2023-07-28T22:40:50.516126Z",
     "iopub.status.idle": "2023-07-28T22:40:50.521493Z",
     "shell.execute_reply": "2023-07-28T22:40:50.520408Z",
     "shell.execute_reply.started": "2023-07-28T22:40:50.516475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the column names for the dataset\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:40:50.880577Z",
     "iopub.status.busy": "2023-07-28T22:40:50.879868Z",
     "iopub.status.idle": "2023-07-28T22:40:56.047669Z",
     "shell.execute_reply": "2023-07-28T22:40:56.046738Z",
     "shell.execute_reply.started": "2023-07-28T22:40:50.880531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the pandas library and read the CSV file into a DataFrame\n",
    "# 'training.1600000.processed.noemoticon 2.csv' is the name of the CSV file\n",
    "# 'iso-8859-1' is the encoding used in the CSV file\n",
    "# DATASET_COLUMNS contains the column names for the DataFrame\n",
    "# This line reads the CSV file and creates a DataFrame called 'dataset'\n",
    "# The 'pd' is an alias for the pandas library\n",
    "dataset = pd.read_csv(\"training.1600000.processed.noemoticon 2.csv\", encoding='iso-8859-1', names=DATASET_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:40:58.682834Z",
     "iopub.status.busy": "2023-07-28T22:40:58.682317Z",
     "iopub.status.idle": "2023-07-28T22:40:58.698912Z",
     "shell.execute_reply": "2023-07-28T22:40:58.697892Z",
     "shell.execute_reply.started": "2023-07-28T22:40:58.682794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset details\n",
    "\n",
    "- target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "- ids: The id of the tweet ( 2087)\n",
    "- date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "- flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "- user: the user that tweeted (robotickilldozr)\n",
    "- text: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:00.519337Z",
     "iopub.status.busy": "2023-07-28T22:41:00.518695Z",
     "iopub.status.idle": "2023-07-28T22:41:00.524060Z",
     "shell.execute_reply": "2023-07-28T22:41:00.522913Z",
     "shell.execute_reply.started": "2023-07-28T22:41:00.519290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:00.787022Z",
     "iopub.status.busy": "2023-07-28T22:41:00.786619Z",
     "iopub.status.idle": "2023-07-28T22:41:00.811994Z",
     "shell.execute_reply": "2023-07-28T22:41:00.810904Z",
     "shell.execute_reply.started": "2023-07-28T22:41:00.786989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#values in target\n",
    "dataset.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:01.030274Z",
     "iopub.status.busy": "2023-07-28T22:41:01.029912Z",
     "iopub.status.idle": "2023-07-28T22:41:01.046432Z",
     "shell.execute_reply": "2023-07-28T22:41:01.045456Z",
     "shell.execute_reply.started": "2023-07-28T22:41:01.030246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print unique values in the 'target' column of the dataset\n",
    "# This line will display the different unique values present in the 'target' column\n",
    "dataset.target.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:01.468592Z",
     "iopub.status.busy": "2023-07-28T22:41:01.468122Z",
     "iopub.status.idle": "2023-07-28T22:41:01.475075Z",
     "shell.execute_reply": "2023-07-28T22:41:01.473760Z",
     "shell.execute_reply.started": "2023-07-28T22:41:01.468543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a dictionary called 'mapping' that maps specific numeric values to sentiment labels.\n",
    "# For example, 0 corresponds to 'Negative', 2 corresponds to 'Neutral', and 4 corresponds to 'Positive'.\n",
    "mapping = {0: 'Negative', 2: 'Neutral', 4: 'Positive'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:01.865088Z",
     "iopub.status.busy": "2023-07-28T22:41:01.864713Z",
     "iopub.status.idle": "2023-07-28T22:41:01.870909Z",
     "shell.execute_reply": "2023-07-28T22:41:01.869694Z",
     "shell.execute_reply.started": "2023-07-28T22:41:01.865060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function called \"converter\" that takes a label as input\n",
    "def converter(label):\n",
    "    # Convert the label to an integer and use it as an index to access the corresponding value from the \"mapping\" dictionary\n",
    "    return mapping[int(label)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:02.447006Z",
     "iopub.status.busy": "2023-07-28T22:41:02.446627Z",
     "iopub.status.idle": "2023-07-28T22:41:03.028799Z",
     "shell.execute_reply": "2023-07-28T22:41:03.027573Z",
     "shell.execute_reply.started": "2023-07-28T22:41:02.446978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the 'converter' function to each element in the 'target' column of the dataset\n",
    "# This function converts each element to a different format\n",
    "dataset.target=dataset.target.apply(lambda x:converter(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:03.196841Z",
     "iopub.status.busy": "2023-07-28T22:41:03.196435Z",
     "iopub.status.idle": "2023-07-28T22:41:03.286707Z",
     "shell.execute_reply": "2023-07-28T22:41:03.285594Z",
     "shell.execute_reply.started": "2023-07-28T22:41:03.196812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Negative    800000\n",
       "postive     800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each target value in the dataset\n",
    "dataset.target.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:03.567863Z",
     "iopub.status.busy": "2023-07-28T22:41:03.567483Z",
     "iopub.status.idle": "2023-07-28T22:41:03.773647Z",
     "shell.execute_reply": "2023-07-28T22:41:03.772390Z",
     "shell.execute_reply.started": "2023-07-28T22:41:03.567833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each target in the dataset\n",
    "target_count=Counter(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:04.014302Z",
     "iopub.status.busy": "2023-07-28T22:41:04.013910Z",
     "iopub.status.idle": "2023-07-28T22:41:04.244891Z",
     "shell.execute_reply": "2023-07-28T22:41:04.243753Z",
     "shell.execute_reply.started": "2023-07-28T22:41:04.014270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(target_count.keys(),target_count.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:04.457422Z",
     "iopub.status.busy": "2023-07-28T22:41:04.457016Z",
     "iopub.status.idle": "2023-07-28T22:41:04.461957Z",
     "shell.execute_reply": "2023-07-28T22:41:04.460756Z",
     "shell.execute_reply.started": "2023-07-28T22:41:04.457387Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preprocessing of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:05.511370Z",
     "iopub.status.busy": "2023-07-28T22:41:05.510987Z",
     "iopub.status.idle": "2023-07-28T22:41:05.517829Z",
     "shell.execute_reply": "2023-07-28T22:41:05.517036Z",
     "shell.execute_reply.started": "2023-07-28T22:41:05.511341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the list of common stop words from the NLTK library\n",
    "# These are words that are often removed from text data as they are considered less informative\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "# Importing the SnowballStemmer from the NLTK library\n",
    "# This is a tool used to reduce words to their base or root form\n",
    "stemmer = SnowballStemmer('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:05.821161Z",
     "iopub.status.busy": "2023-07-28T22:41:05.820486Z",
     "iopub.status.idle": "2023-07-28T22:41:05.826474Z",
     "shell.execute_reply": "2023-07-28T22:41:05.825225Z",
     "shell.execute_reply.started": "2023-07-28T22:41:05.821126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regular expression pattern to match usernames starting with '@' and URLs starting with 'http' or 'https'\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:06.444892Z",
     "iopub.status.busy": "2023-07-28T22:41:06.444516Z",
     "iopub.status.idle": "2023-07-28T22:41:06.452015Z",
     "shell.execute_reply": "2023-07-28T22:41:06.450892Z",
     "shell.execute_reply.started": "2023-07-28T22:41:06.444856Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove links, usernames, and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    \n",
    "    # Initialize an empty list to store processed tokens\n",
    "    tokens = []\n",
    "    \n",
    "    # Split the text into individual words and process each word\n",
    "    for token in text.split():\n",
    "        # Check if the token is not in the list of stop words\n",
    "        if token not in stop_words:\n",
    "            # If stem is set to True, apply stemming to the token\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                # If stem is set to False, keep the token as is\n",
    "                tokens.append(token)\n",
    "    \n",
    "    # Join the processed tokens back into a single string and return it\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:07.276043Z",
     "iopub.status.busy": "2023-07-28T22:41:07.275679Z",
     "iopub.status.idle": "2023-07-28T22:41:56.055128Z",
     "shell.execute_reply": "2023-07-28T22:41:56.054013Z",
     "shell.execute_reply.started": "2023-07-28T22:41:07.276015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the preprocess function to each element in the 'text' column of the dataset\n",
    "dataset.text = dataset.text.apply(lambda x: preprocess(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:41:56.057927Z",
     "iopub.status.busy": "2023-07-28T22:41:56.057494Z",
     "iopub.status.idle": "2023-07-28T22:41:56.065670Z",
     "shell.execute_reply": "2023-07-28T22:41:56.064670Z",
     "shell.execute_reply.started": "2023-07-28T22:41:56.057880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dived many times ball. managed save 50% rest go bounds'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.text[2]  # Accessing the text data at index 2 from the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:42:00.349479Z",
     "iopub.status.busy": "2023-07-28T22:42:00.349092Z",
     "iopub.status.idle": "2023-07-28T22:42:02.064687Z",
     "shell.execute_reply": "2023-07-28T22:42:02.063398Z",
     "shell.execute_reply.started": "2023-07-28T22:42:00.349449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the 'dataset' into training and testing sets\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2, random_state=43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:42:02.067896Z",
     "iopub.status.busy": "2023-07-28T22:42:02.066699Z",
     "iopub.status.idle": "2023-07-28T22:42:02.075169Z",
     "shell.execute_reply": "2023-07-28T22:42:02.073915Z",
     "shell.execute_reply.started": "2023-07-28T22:42:02.067848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the DataFrame 'df_train'\n",
    "df_train.shape  # Returns the number of rows and columns in the DataFrame 'df_train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:42:02.077187Z",
     "iopub.status.busy": "2023-07-28T22:42:02.076677Z",
     "iopub.status.idle": "2023-07-28T22:42:02.106011Z",
     "shell.execute_reply": "2023-07-28T22:42:02.104899Z",
     "shell.execute_reply.started": "2023-07-28T22:42:02.077145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320000, 6)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape# Get the shape of the DataFrame 'df_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:42:41.036912Z",
     "iopub.status.busy": "2023-07-28T22:42:41.036494Z",
     "iopub.status.idle": "2023-07-28T22:42:41.049514Z",
     "shell.execute_reply": "2023-07-28T22:42:41.048495Z",
     "shell.execute_reply.started": "2023-07-28T22:42:41.036881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1141602</th>\n",
       "      <td>postive</td>\n",
       "      <td>1977196970</td>\n",
       "      <td>Sat May 30 20:21:10 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rkfairchild</td>\n",
       "      <td>dont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746804</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2283288335</td>\n",
       "      <td>Mon Jun 22 12:26:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>llinndsseyy</td>\n",
       "      <td>woke mom. wired ass dream... first part nice, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115767</th>\n",
       "      <td>postive</td>\n",
       "      <td>1973022029</td>\n",
       "      <td>Sat May 30 10:19:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SandraCha</td>\n",
       "      <td>good afternoon everyone def. going fishing today!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961669</th>\n",
       "      <td>postive</td>\n",
       "      <td>1827125829</td>\n",
       "      <td>Sun May 17 10:02:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mssBOOTZ</td>\n",
       "      <td>10:02am | morning dawlings ! hope everyone goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351157</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2018270043</td>\n",
       "      <td>Wed Jun 03 09:42:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iAmTheUrbanL</td>\n",
       "      <td>u guys fix speed option cuz speeding game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target         ids                          date      flag  \\\n",
       "1141602   postive  1977196970  Sat May 30 20:21:10 PDT 2009  NO_QUERY   \n",
       "746804   Negative  2283288335  Mon Jun 22 12:26:21 PDT 2009  NO_QUERY   \n",
       "1115767   postive  1973022029  Sat May 30 10:19:43 PDT 2009  NO_QUERY   \n",
       "961669    postive  1827125829  Sun May 17 10:02:50 PDT 2009  NO_QUERY   \n",
       "351157   Negative  2018270043  Wed Jun 03 09:42:13 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \n",
       "1141602   rkfairchild                                               dont  \n",
       "746804    llinndsseyy  woke mom. wired ass dream... first part nice, ...  \n",
       "1115767     SandraCha  good afternoon everyone def. going fishing today!  \n",
       "961669       mssBOOTZ  10:02am | morning dawlings ! hope everyone goo...  \n",
       "351157   iAmTheUrbanL          u guys fix speed option cuz speeding game  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:42:56.321642Z",
     "iopub.status.busy": "2023-07-28T22:42:56.321256Z",
     "iopub.status.idle": "2023-07-28T22:42:56.492579Z",
     "shell.execute_reply": "2023-07-28T22:42:56.491417Z",
     "shell.execute_reply.started": "2023-07-28T22:42:56.321614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont\n"
     ]
    }
   ],
   "source": [
    "for _text in df_train.text:\n",
    "    print(_text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:45:49.900621Z",
     "iopub.status.busy": "2023-07-28T22:45:49.900171Z",
     "iopub.status.idle": "2023-07-28T22:45:54.432952Z",
     "shell.execute_reply": "2023-07-28T22:45:54.429468Z",
     "shell.execute_reply.started": "2023-07-28T22:45:49.900586Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = [_text.split() for _text in df_train.text]  # Split each text in df_train into a list of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:50:24.188241Z",
     "iopub.status.busy": "2023-07-28T22:50:24.187010Z",
     "iopub.status.idle": "2023-07-28T22:52:13.674242Z",
     "shell.execute_reply": "2023-07-28T22:52:13.673004Z",
     "shell.execute_reply.started": "2023-07-28T22:50:24.188198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement genism (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for genism\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install genism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:56:19.594151Z",
     "iopub.status.busy": "2023-07-28T22:56:19.593776Z",
     "iopub.status.idle": "2023-07-28T22:56:19.601938Z",
     "shell.execute_reply": "2023-07-28T22:56:19.600319Z",
     "shell.execute_reply.started": "2023-07-28T22:56:19.594122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 16:33:21,988 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.025>', 'datetime': '2023-08-05T16:33:21.988336', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Create a Word2Vec model using the gensim library\n",
    "word2vec = gensim.models.word2vec.Word2Vec(\n",
    "    vector_size=300,  # The dimensionality of the word vectors\n",
    "    window=6,         # The maximum distance between the current and predicted word within a sentence\n",
    "    min_count=8,      # Minimum number of occurrences of a word to be included in the vocabulary\n",
    "    workers=8         # Number of CPU cores to use for training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T22:57:47.315622Z",
     "iopub.status.busy": "2023-07-28T22:57:47.315185Z",
     "iopub.status.idle": "2023-07-28T22:57:52.162823Z",
     "shell.execute_reply": "2023-07-28T22:57:52.161673Z",
     "shell.execute_reply.started": "2023-07-28T22:57:47.315585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 16:33:21,994 : INFO : collecting all words and their counts\n",
      "2023-08-05 16:33:21,995 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-08-05 16:33:22,013 : INFO : PROGRESS: at sentence #10000, processed 75662 words, keeping 21482 word types\n",
      "2023-08-05 16:33:22,027 : INFO : PROGRESS: at sentence #20000, processed 151132 words, keeping 35320 word types\n",
      "2023-08-05 16:33:22,039 : INFO : PROGRESS: at sentence #30000, processed 226418 words, keeping 47034 word types\n",
      "2023-08-05 16:33:22,050 : INFO : PROGRESS: at sentence #40000, processed 301611 words, keeping 57556 word types\n",
      "2023-08-05 16:33:22,065 : INFO : PROGRESS: at sentence #50000, processed 377440 words, keeping 67418 word types\n",
      "2023-08-05 16:33:22,077 : INFO : PROGRESS: at sentence #60000, processed 453687 words, keeping 76822 word types\n",
      "2023-08-05 16:33:22,091 : INFO : PROGRESS: at sentence #70000, processed 529809 words, keeping 85596 word types\n",
      "2023-08-05 16:33:22,106 : INFO : PROGRESS: at sentence #80000, processed 605751 words, keeping 93830 word types\n",
      "2023-08-05 16:33:22,117 : INFO : PROGRESS: at sentence #90000, processed 681927 words, keeping 101997 word types\n",
      "2023-08-05 16:33:22,132 : INFO : PROGRESS: at sentence #100000, processed 757554 words, keeping 109868 word types\n",
      "2023-08-05 16:33:22,145 : INFO : PROGRESS: at sentence #110000, processed 832673 words, keeping 117362 word types\n",
      "2023-08-05 16:33:22,159 : INFO : PROGRESS: at sentence #120000, processed 907697 words, keeping 124800 word types\n",
      "2023-08-05 16:33:22,172 : INFO : PROGRESS: at sentence #130000, processed 983092 words, keeping 132130 word types\n",
      "2023-08-05 16:33:22,184 : INFO : PROGRESS: at sentence #140000, processed 1058762 words, keeping 139344 word types\n",
      "2023-08-05 16:33:22,199 : INFO : PROGRESS: at sentence #150000, processed 1135088 words, keeping 146274 word types\n",
      "2023-08-05 16:33:22,214 : INFO : PROGRESS: at sentence #160000, processed 1210555 words, keeping 153226 word types\n",
      "2023-08-05 16:33:22,230 : INFO : PROGRESS: at sentence #170000, processed 1286836 words, keeping 160025 word types\n",
      "2023-08-05 16:33:22,245 : INFO : PROGRESS: at sentence #180000, processed 1362335 words, keeping 166378 word types\n",
      "2023-08-05 16:33:22,260 : INFO : PROGRESS: at sentence #190000, processed 1438656 words, keeping 172974 word types\n",
      "2023-08-05 16:33:22,275 : INFO : PROGRESS: at sentence #200000, processed 1513533 words, keeping 179308 word types\n",
      "2023-08-05 16:33:22,290 : INFO : PROGRESS: at sentence #210000, processed 1589260 words, keeping 185505 word types\n",
      "2023-08-05 16:33:22,304 : INFO : PROGRESS: at sentence #220000, processed 1665190 words, keeping 191740 word types\n",
      "2023-08-05 16:33:22,321 : INFO : PROGRESS: at sentence #230000, processed 1741679 words, keeping 197831 word types\n",
      "2023-08-05 16:33:22,336 : INFO : PROGRESS: at sentence #240000, processed 1817914 words, keeping 203802 word types\n",
      "2023-08-05 16:33:22,350 : INFO : PROGRESS: at sentence #250000, processed 1893492 words, keeping 209704 word types\n",
      "2023-08-05 16:33:22,365 : INFO : PROGRESS: at sentence #260000, processed 1969483 words, keeping 215518 word types\n",
      "2023-08-05 16:33:22,378 : INFO : PROGRESS: at sentence #270000, processed 2045731 words, keeping 221326 word types\n",
      "2023-08-05 16:33:22,394 : INFO : PROGRESS: at sentence #280000, processed 2121706 words, keeping 227002 word types\n",
      "2023-08-05 16:33:22,409 : INFO : PROGRESS: at sentence #290000, processed 2197917 words, keeping 232728 word types\n",
      "2023-08-05 16:33:22,424 : INFO : PROGRESS: at sentence #300000, processed 2274049 words, keeping 238284 word types\n",
      "2023-08-05 16:33:22,438 : INFO : PROGRESS: at sentence #310000, processed 2349710 words, keeping 243820 word types\n",
      "2023-08-05 16:33:22,455 : INFO : PROGRESS: at sentence #320000, processed 2425746 words, keeping 249382 word types\n",
      "2023-08-05 16:33:22,468 : INFO : PROGRESS: at sentence #330000, processed 2500735 words, keeping 254873 word types\n",
      "2023-08-05 16:33:22,483 : INFO : PROGRESS: at sentence #340000, processed 2576432 words, keeping 260143 word types\n",
      "2023-08-05 16:33:22,499 : INFO : PROGRESS: at sentence #350000, processed 2652240 words, keeping 265392 word types\n",
      "2023-08-05 16:33:22,513 : INFO : PROGRESS: at sentence #360000, processed 2727973 words, keeping 270755 word types\n",
      "2023-08-05 16:33:22,528 : INFO : PROGRESS: at sentence #370000, processed 2803457 words, keeping 275835 word types\n",
      "2023-08-05 16:33:22,542 : INFO : PROGRESS: at sentence #380000, processed 2878538 words, keeping 280890 word types\n",
      "2023-08-05 16:33:22,556 : INFO : PROGRESS: at sentence #390000, processed 2953920 words, keeping 286054 word types\n",
      "2023-08-05 16:33:22,570 : INFO : PROGRESS: at sentence #400000, processed 3029072 words, keeping 290983 word types\n",
      "2023-08-05 16:33:22,586 : INFO : PROGRESS: at sentence #410000, processed 3104136 words, keeping 295874 word types\n",
      "2023-08-05 16:33:22,600 : INFO : PROGRESS: at sentence #420000, processed 3179829 words, keeping 300956 word types\n",
      "2023-08-05 16:33:22,615 : INFO : PROGRESS: at sentence #430000, processed 3255510 words, keeping 306053 word types\n",
      "2023-08-05 16:33:22,631 : INFO : PROGRESS: at sentence #440000, processed 3331669 words, keeping 310877 word types\n",
      "2023-08-05 16:33:22,645 : INFO : PROGRESS: at sentence #450000, processed 3407869 words, keeping 315855 word types\n",
      "2023-08-05 16:33:22,659 : INFO : PROGRESS: at sentence #460000, processed 3483209 words, keeping 320689 word types\n",
      "2023-08-05 16:33:22,676 : INFO : PROGRESS: at sentence #470000, processed 3559806 words, keeping 325603 word types\n",
      "2023-08-05 16:33:22,691 : INFO : PROGRESS: at sentence #480000, processed 3635056 words, keeping 330501 word types\n",
      "2023-08-05 16:33:22,706 : INFO : PROGRESS: at sentence #490000, processed 3710541 words, keeping 335317 word types\n",
      "2023-08-05 16:33:22,720 : INFO : PROGRESS: at sentence #500000, processed 3786588 words, keeping 340191 word types\n",
      "2023-08-05 16:33:22,736 : INFO : PROGRESS: at sentence #510000, processed 3862536 words, keeping 345060 word types\n",
      "2023-08-05 16:33:22,756 : INFO : PROGRESS: at sentence #520000, processed 3937914 words, keeping 349842 word types\n",
      "2023-08-05 16:33:22,773 : INFO : PROGRESS: at sentence #530000, processed 4013487 words, keeping 354478 word types\n",
      "2023-08-05 16:33:22,790 : INFO : PROGRESS: at sentence #540000, processed 4088657 words, keeping 359132 word types\n",
      "2023-08-05 16:33:22,806 : INFO : PROGRESS: at sentence #550000, processed 4164742 words, keeping 363845 word types\n",
      "2023-08-05 16:33:22,823 : INFO : PROGRESS: at sentence #560000, processed 4240455 words, keeping 368544 word types\n",
      "2023-08-05 16:33:22,840 : INFO : PROGRESS: at sentence #570000, processed 4315625 words, keeping 373203 word types\n",
      "2023-08-05 16:33:22,856 : INFO : PROGRESS: at sentence #580000, processed 4392061 words, keeping 377760 word types\n",
      "2023-08-05 16:33:22,873 : INFO : PROGRESS: at sentence #590000, processed 4467950 words, keeping 382384 word types\n",
      "2023-08-05 16:33:22,889 : INFO : PROGRESS: at sentence #600000, processed 4543268 words, keeping 386916 word types\n",
      "2023-08-05 16:33:22,903 : INFO : PROGRESS: at sentence #610000, processed 4619115 words, keeping 391590 word types\n",
      "2023-08-05 16:33:22,919 : INFO : PROGRESS: at sentence #620000, processed 4694618 words, keeping 396181 word types\n",
      "2023-08-05 16:33:22,933 : INFO : PROGRESS: at sentence #630000, processed 4770049 words, keeping 400676 word types\n",
      "2023-08-05 16:33:22,949 : INFO : PROGRESS: at sentence #640000, processed 4845472 words, keeping 405106 word types\n",
      "2023-08-05 16:33:22,964 : INFO : PROGRESS: at sentence #650000, processed 4920277 words, keeping 409538 word types\n",
      "2023-08-05 16:33:22,978 : INFO : PROGRESS: at sentence #660000, processed 4996209 words, keeping 413918 word types\n",
      "2023-08-05 16:33:22,995 : INFO : PROGRESS: at sentence #670000, processed 5072465 words, keeping 418304 word types\n",
      "2023-08-05 16:33:23,012 : INFO : PROGRESS: at sentence #680000, processed 5148193 words, keeping 422781 word types\n",
      "2023-08-05 16:33:23,029 : INFO : PROGRESS: at sentence #690000, processed 5224360 words, keeping 427232 word types\n",
      "2023-08-05 16:33:23,043 : INFO : PROGRESS: at sentence #700000, processed 5300985 words, keeping 431592 word types\n",
      "2023-08-05 16:33:23,062 : INFO : PROGRESS: at sentence #710000, processed 5377522 words, keeping 435913 word types\n",
      "2023-08-05 16:33:23,078 : INFO : PROGRESS: at sentence #720000, processed 5453654 words, keeping 440334 word types\n",
      "2023-08-05 16:33:23,094 : INFO : PROGRESS: at sentence #730000, processed 5529257 words, keeping 444748 word types\n",
      "2023-08-05 16:33:23,108 : INFO : PROGRESS: at sentence #740000, processed 5605726 words, keeping 448984 word types\n",
      "2023-08-05 16:33:23,127 : INFO : PROGRESS: at sentence #750000, processed 5681214 words, keeping 453327 word types\n",
      "2023-08-05 16:33:23,143 : INFO : PROGRESS: at sentence #760000, processed 5756901 words, keeping 457439 word types\n",
      "2023-08-05 16:33:23,160 : INFO : PROGRESS: at sentence #770000, processed 5832592 words, keeping 461637 word types\n",
      "2023-08-05 16:33:23,175 : INFO : PROGRESS: at sentence #780000, processed 5907989 words, keeping 465769 word types\n",
      "2023-08-05 16:33:23,192 : INFO : PROGRESS: at sentence #790000, processed 5983338 words, keeping 470049 word types\n",
      "2023-08-05 16:33:23,206 : INFO : PROGRESS: at sentence #800000, processed 6059072 words, keeping 474220 word types\n",
      "2023-08-05 16:33:23,225 : INFO : PROGRESS: at sentence #810000, processed 6135055 words, keeping 478404 word types\n",
      "2023-08-05 16:33:23,241 : INFO : PROGRESS: at sentence #820000, processed 6210589 words, keeping 482572 word types\n",
      "2023-08-05 16:33:23,257 : INFO : PROGRESS: at sentence #830000, processed 6286014 words, keeping 486701 word types\n",
      "2023-08-05 16:33:23,275 : INFO : PROGRESS: at sentence #840000, processed 6361776 words, keeping 490894 word types\n",
      "2023-08-05 16:33:23,293 : INFO : PROGRESS: at sentence #850000, processed 6438094 words, keeping 495062 word types\n",
      "2023-08-05 16:33:23,308 : INFO : PROGRESS: at sentence #860000, processed 6512740 words, keeping 499090 word types\n",
      "2023-08-05 16:33:23,324 : INFO : PROGRESS: at sentence #870000, processed 6588922 words, keeping 503255 word types\n",
      "2023-08-05 16:33:23,339 : INFO : PROGRESS: at sentence #880000, processed 6664818 words, keeping 507283 word types\n",
      "2023-08-05 16:33:23,355 : INFO : PROGRESS: at sentence #890000, processed 6740666 words, keeping 511247 word types\n",
      "2023-08-05 16:33:23,371 : INFO : PROGRESS: at sentence #900000, processed 6816638 words, keeping 515328 word types\n",
      "2023-08-05 16:33:23,387 : INFO : PROGRESS: at sentence #910000, processed 6891788 words, keeping 519359 word types\n",
      "2023-08-05 16:33:23,404 : INFO : PROGRESS: at sentence #920000, processed 6967039 words, keeping 523224 word types\n",
      "2023-08-05 16:33:23,420 : INFO : PROGRESS: at sentence #930000, processed 7043045 words, keeping 527145 word types\n",
      "2023-08-05 16:33:23,437 : INFO : PROGRESS: at sentence #940000, processed 7118922 words, keeping 531168 word types\n",
      "2023-08-05 16:33:23,453 : INFO : PROGRESS: at sentence #950000, processed 7194655 words, keeping 535140 word types\n",
      "2023-08-05 16:33:23,470 : INFO : PROGRESS: at sentence #960000, processed 7270359 words, keeping 539147 word types\n",
      "2023-08-05 16:33:23,485 : INFO : PROGRESS: at sentence #970000, processed 7346784 words, keeping 543203 word types\n",
      "2023-08-05 16:33:23,503 : INFO : PROGRESS: at sentence #980000, processed 7422333 words, keeping 547274 word types\n",
      "2023-08-05 16:33:23,519 : INFO : PROGRESS: at sentence #990000, processed 7498144 words, keeping 551179 word types\n",
      "2023-08-05 16:33:23,534 : INFO : PROGRESS: at sentence #1000000, processed 7574224 words, keeping 555169 word types\n",
      "2023-08-05 16:33:23,551 : INFO : PROGRESS: at sentence #1010000, processed 7649447 words, keeping 558986 word types\n",
      "2023-08-05 16:33:23,568 : INFO : PROGRESS: at sentence #1020000, processed 7725185 words, keeping 562950 word types\n",
      "2023-08-05 16:33:23,584 : INFO : PROGRESS: at sentence #1030000, processed 7800289 words, keeping 566797 word types\n",
      "2023-08-05 16:33:23,600 : INFO : PROGRESS: at sentence #1040000, processed 7875385 words, keeping 570675 word types\n",
      "2023-08-05 16:33:23,615 : INFO : PROGRESS: at sentence #1050000, processed 7951642 words, keeping 574607 word types\n",
      "2023-08-05 16:33:23,630 : INFO : PROGRESS: at sentence #1060000, processed 8027390 words, keeping 578589 word types\n",
      "2023-08-05 16:33:23,646 : INFO : PROGRESS: at sentence #1070000, processed 8102936 words, keeping 582381 word types\n",
      "2023-08-05 16:33:23,663 : INFO : PROGRESS: at sentence #1080000, processed 8179443 words, keeping 586289 word types\n",
      "2023-08-05 16:33:23,678 : INFO : PROGRESS: at sentence #1090000, processed 8255171 words, keeping 590136 word types\n",
      "2023-08-05 16:33:23,694 : INFO : PROGRESS: at sentence #1100000, processed 8330573 words, keeping 593869 word types\n",
      "2023-08-05 16:33:23,710 : INFO : PROGRESS: at sentence #1110000, processed 8406865 words, keeping 597729 word types\n",
      "2023-08-05 16:33:23,726 : INFO : PROGRESS: at sentence #1120000, processed 8482980 words, keeping 601532 word types\n",
      "2023-08-05 16:33:23,743 : INFO : PROGRESS: at sentence #1130000, processed 8558406 words, keeping 605257 word types\n",
      "2023-08-05 16:33:23,760 : INFO : PROGRESS: at sentence #1140000, processed 8634665 words, keeping 609075 word types\n",
      "2023-08-05 16:33:23,776 : INFO : PROGRESS: at sentence #1150000, processed 8710447 words, keeping 612813 word types\n",
      "2023-08-05 16:33:23,793 : INFO : PROGRESS: at sentence #1160000, processed 8786964 words, keeping 616602 word types\n",
      "2023-08-05 16:33:23,807 : INFO : PROGRESS: at sentence #1170000, processed 8862406 words, keeping 620427 word types\n",
      "2023-08-05 16:33:23,821 : INFO : PROGRESS: at sentence #1180000, processed 8937954 words, keeping 624268 word types\n",
      "2023-08-05 16:33:23,839 : INFO : PROGRESS: at sentence #1190000, processed 9013441 words, keeping 628029 word types\n",
      "2023-08-05 16:33:23,854 : INFO : PROGRESS: at sentence #1200000, processed 9089265 words, keeping 631832 word types\n",
      "2023-08-05 16:33:23,872 : INFO : PROGRESS: at sentence #1210000, processed 9165443 words, keeping 635569 word types\n",
      "2023-08-05 16:33:23,889 : INFO : PROGRESS: at sentence #1220000, processed 9241915 words, keeping 639215 word types\n",
      "2023-08-05 16:33:23,907 : INFO : PROGRESS: at sentence #1230000, processed 9317436 words, keeping 642772 word types\n",
      "2023-08-05 16:33:23,925 : INFO : PROGRESS: at sentence #1240000, processed 9393512 words, keeping 646461 word types\n",
      "2023-08-05 16:33:23,940 : INFO : PROGRESS: at sentence #1250000, processed 9469744 words, keeping 650231 word types\n",
      "2023-08-05 16:33:23,957 : INFO : PROGRESS: at sentence #1260000, processed 9545436 words, keeping 653718 word types\n",
      "2023-08-05 16:33:23,973 : INFO : PROGRESS: at sentence #1270000, processed 9621007 words, keeping 657337 word types\n",
      "2023-08-05 16:33:23,989 : INFO : collected 661099 word types from a corpus of 9696489 raw words and 1280000 sentences\n",
      "2023-08-05 16:33:23,990 : INFO : Creating a fresh vocabulary\n",
      "2023-08-05 16:33:24,180 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=8 retains 55483 unique words (8.39% of original 661099, drops 605616)', 'datetime': '2023-08-05T16:33:24.180765', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-08-05 16:33:24,181 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 8793551 word corpus (90.69% of original 9696489, drops 902938)', 'datetime': '2023-08-05T16:33:24.181124', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-08-05 16:33:24,303 : INFO : deleting the raw counts dictionary of 661099 items\n",
      "2023-08-05 16:33:24,308 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2023-08-05 16:33:24,309 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8352339.234005696 word corpus (95.0%% of prior 8793551)', 'datetime': '2023-08-05T16:33:24.309434', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-08-05 16:33:24,508 : INFO : estimated required memory for 55483 words and 300 dimensions: 160900700 bytes\n",
      "2023-08-05 16:33:24,508 : INFO : resetting layer weights\n",
      "2023-08-05 16:33:24,565 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-08-05T16:33:24.565079', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "word2vec.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:02:56.498101Z",
     "iopub.status.busy": "2023-07-28T23:02:56.497706Z",
     "iopub.status.idle": "2023-07-28T23:02:56.504055Z",
     "shell.execute_reply": "2023-07-28T23:02:56.502999Z",
     "shell.execute_reply.started": "2023-07-28T23:02:56.498071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 55483\n"
     ]
    }
   ],
   "source": [
    "# Get the list of words from the word2vec model's index\n",
    "words = word2vec.wv.index_to_key\n",
    "\n",
    "# Calculate the size of the vocabulary by counting the number of words\n",
    "vocab_size = len(words)\n",
    "\n",
    "# Print the calculated vocabulary size\n",
    "print(\"Vocab size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:04:53.901953Z",
     "iopub.status.busy": "2023-07-28T23:04:53.901534Z",
     "iopub.status.idle": "2023-07-28T23:04:53.908556Z",
     "shell.execute_reply": "2023-07-28T23:04:53.907515Z",
     "shell.execute_reply.started": "2023-07-28T23:04:53.901923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:05:10.841837Z",
     "iopub.status.busy": "2023-07-28T23:05:10.841296Z",
     "iopub.status.idle": "2023-07-28T23:05:10.849975Z",
     "shell.execute_reply": "2023-07-28T23:05:10.848703Z",
     "shell.execute_reply.started": "2023-07-28T23:05:10.841792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:06:28.787913Z",
     "iopub.status.busy": "2023-07-28T23:06:28.787517Z",
     "iopub.status.idle": "2023-07-28T23:06:28.792837Z",
     "shell.execute_reply": "2023-07-28T23:06:28.791792Z",
     "shell.execute_reply.started": "2023-07-28T23:06:28.787881Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:09:10.811141Z",
     "iopub.status.busy": "2023-07-28T23:09:10.810773Z",
     "iopub.status.idle": "2023-07-28T23:09:10.815897Z",
     "shell.execute_reply": "2023-07-28T23:09:10.814896Z",
     "shell.execute_reply.started": "2023-07-28T23:09:10.811113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2f23ec910>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 16:33:24,590 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 55483 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6 shrink_windows=True', 'datetime': '2023-08-05T16:33:24.590837', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-08-05 16:33:25,609 : INFO : EPOCH 0 - PROGRESS: at 24.62% examples, 2051960 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:26,615 : INFO : EPOCH 0 - PROGRESS: at 49.30% examples, 2049936 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:27,618 : INFO : EPOCH 0 - PROGRESS: at 74.24% examples, 2058594 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:28,625 : INFO : EPOCH 0 - PROGRESS: at 98.96% examples, 2056865 words/s, in_qsize 11, out_qsize 0\n",
      "2023-08-05 16:33:28,659 : INFO : EPOCH 0: training on 9696489 raw words (8351739 effective words) took 4.1s, 2061198 effective words/s\n",
      "2023-08-05 16:33:29,671 : INFO : EPOCH 1 - PROGRESS: at 24.52% examples, 2045992 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:33:30,672 : INFO : EPOCH 1 - PROGRESS: at 50.02% examples, 2085282 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:31,679 : INFO : EPOCH 1 - PROGRESS: at 75.37% examples, 2091205 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:32,627 : INFO : EPOCH 1: training on 9696489 raw words (8351714 effective words) took 4.0s, 2109924 effective words/s\n",
      "2023-08-05 16:33:33,643 : INFO : EPOCH 2 - PROGRESS: at 25.24% examples, 2096758 words/s, in_qsize 16, out_qsize 1\n",
      "2023-08-05 16:33:34,646 : INFO : EPOCH 2 - PROGRESS: at 51.06% examples, 2121124 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:33:35,649 : INFO : EPOCH 2 - PROGRESS: at 76.61% examples, 2123668 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:33:36,560 : INFO : EPOCH 2: training on 9696489 raw words (8351246 effective words) took 3.9s, 2128704 effective words/s\n",
      "2023-08-05 16:33:37,579 : INFO : EPOCH 3 - PROGRESS: at 25.03% examples, 2083410 words/s, in_qsize 16, out_qsize 1\n",
      "2023-08-05 16:33:38,583 : INFO : EPOCH 3 - PROGRESS: at 50.55% examples, 2101235 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:39,586 : INFO : EPOCH 3 - PROGRESS: at 76.20% examples, 2113484 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:40,506 : INFO : EPOCH 3: training on 9696489 raw words (8352191 effective words) took 3.9s, 2124794 effective words/s\n",
      "2023-08-05 16:33:41,515 : INFO : EPOCH 4 - PROGRESS: at 24.62% examples, 2054514 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:42,517 : INFO : EPOCH 4 - PROGRESS: at 50.24% examples, 2092578 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:43,519 : INFO : EPOCH 4 - PROGRESS: at 75.37% examples, 2094202 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:44,474 : INFO : EPOCH 4: training on 9696489 raw words (8351859 effective words) took 4.0s, 2108481 effective words/s\n",
      "2023-08-05 16:33:45,490 : INFO : EPOCH 5 - PROGRESS: at 24.93% examples, 2070830 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:46,490 : INFO : EPOCH 5 - PROGRESS: at 50.44% examples, 2099191 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:33:47,494 : INFO : EPOCH 5 - PROGRESS: at 75.99% examples, 2108287 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:48,423 : INFO : EPOCH 5: training on 9696489 raw words (8352761 effective words) took 3.9s, 2120528 effective words/s\n",
      "2023-08-05 16:33:49,439 : INFO : EPOCH 6 - PROGRESS: at 25.14% examples, 2087831 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:50,442 : INFO : EPOCH 6 - PROGRESS: at 50.65% examples, 2103818 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:51,448 : INFO : EPOCH 6 - PROGRESS: at 76.09% examples, 2107133 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:52,386 : INFO : EPOCH 6: training on 9696489 raw words (8352858 effective words) took 4.0s, 2112522 effective words/s\n",
      "2023-08-05 16:33:53,407 : INFO : EPOCH 7 - PROGRESS: at 25.14% examples, 2077538 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:33:54,408 : INFO : EPOCH 7 - PROGRESS: at 50.65% examples, 2101519 words/s, in_qsize 15, out_qsize 1\n",
      "2023-08-05 16:33:55,411 : INFO : EPOCH 7 - PROGRESS: at 75.89% examples, 2101948 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:56,345 : INFO : EPOCH 7: training on 9696489 raw words (8352436 effective words) took 3.9s, 2115098 effective words/s\n",
      "2023-08-05 16:33:57,354 : INFO : EPOCH 8 - PROGRESS: at 24.93% examples, 2082649 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:33:58,356 : INFO : EPOCH 8 - PROGRESS: at 50.55% examples, 2107740 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:33:59,361 : INFO : EPOCH 8 - PROGRESS: at 76.09% examples, 2113151 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:00,285 : INFO : EPOCH 8: training on 9696489 raw words (8352515 effective words) took 3.9s, 2124600 effective words/s\n",
      "2023-08-05 16:34:01,296 : INFO : EPOCH 9 - PROGRESS: at 24.72% examples, 2062997 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:02,299 : INFO : EPOCH 9 - PROGRESS: at 50.34% examples, 2096989 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:03,299 : INFO : EPOCH 9 - PROGRESS: at 76.09% examples, 2115320 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:04,230 : INFO : EPOCH 9: training on 9696489 raw words (8352957 effective words) took 3.9s, 2122572 effective words/s\n",
      "2023-08-05 16:34:05,241 : INFO : EPOCH 10 - PROGRESS: at 25.24% examples, 2106020 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:06,243 : INFO : EPOCH 10 - PROGRESS: at 51.06% examples, 2126759 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:07,251 : INFO : EPOCH 10 - PROGRESS: at 76.61% examples, 2124212 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:08,159 : INFO : EPOCH 10: training on 9696489 raw words (8351767 effective words) took 3.9s, 2130868 effective words/s\n",
      "2023-08-05 16:34:09,170 : INFO : EPOCH 11 - PROGRESS: at 24.52% examples, 2041704 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:10,172 : INFO : EPOCH 11 - PROGRESS: at 50.13% examples, 2086296 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:11,179 : INFO : EPOCH 11 - PROGRESS: at 75.68% examples, 2097896 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:12,122 : INFO : EPOCH 11: training on 9696489 raw words (8352883 effective words) took 4.0s, 2111495 effective words/s\n",
      "2023-08-05 16:34:13,137 : INFO : EPOCH 12 - PROGRESS: at 25.14% examples, 2088789 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:14,139 : INFO : EPOCH 12 - PROGRESS: at 50.76% examples, 2110609 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:15,142 : INFO : EPOCH 12 - PROGRESS: at 75.99% examples, 2107908 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:16,066 : INFO : EPOCH 12: training on 9696489 raw words (8352784 effective words) took 3.9s, 2122935 effective words/s\n",
      "2023-08-05 16:34:17,075 : INFO : EPOCH 13 - PROGRESS: at 24.83% examples, 2074897 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:18,075 : INFO : EPOCH 13 - PROGRESS: at 50.34% examples, 2100794 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:19,077 : INFO : EPOCH 13 - PROGRESS: at 75.68% examples, 2104762 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:20,035 : INFO : EPOCH 13: training on 9696489 raw words (8352150 effective words) took 4.0s, 2109138 effective words/s\n",
      "2023-08-05 16:34:21,045 : INFO : EPOCH 14 - PROGRESS: at 24.31% examples, 2028657 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:22,051 : INFO : EPOCH 14 - PROGRESS: at 49.41% examples, 2054712 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:23,057 : INFO : EPOCH 14 - PROGRESS: at 75.06% examples, 2080019 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:24,029 : INFO : EPOCH 14: training on 9696489 raw words (8352226 effective words) took 4.0s, 2095616 effective words/s\n",
      "2023-08-05 16:34:25,042 : INFO : EPOCH 15 - PROGRESS: at 25.14% examples, 2092986 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:26,047 : INFO : EPOCH 15 - PROGRESS: at 50.86% examples, 2114125 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:27,050 : INFO : EPOCH 15 - PROGRESS: at 76.51% examples, 2121374 words/s, in_qsize 16, out_qsize 1\n",
      "2023-08-05 16:34:27,959 : INFO : EPOCH 15: training on 9696489 raw words (8352581 effective words) took 3.9s, 2130292 effective words/s\n",
      "2023-08-05 16:34:28,970 : INFO : EPOCH 16 - PROGRESS: at 24.93% examples, 2081928 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:29,971 : INFO : EPOCH 16 - PROGRESS: at 50.44% examples, 2102981 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:30,976 : INFO : EPOCH 16 - PROGRESS: at 75.99% examples, 2110690 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:31,910 : INFO : EPOCH 16: training on 9696489 raw words (8353176 effective words) took 3.9s, 2119692 effective words/s\n",
      "2023-08-05 16:34:32,927 : INFO : EPOCH 17 - PROGRESS: at 25.13% examples, 2096598 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:33,927 : INFO : EPOCH 17 - PROGRESS: at 50.86% examples, 2120258 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:34,930 : INFO : EPOCH 17 - PROGRESS: at 76.51% examples, 2125982 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:34:35,839 : INFO : EPOCH 17: training on 9696489 raw words (8351793 effective words) took 3.9s, 2134195 effective words/s\n",
      "2023-08-05 16:34:36,850 : INFO : EPOCH 18 - PROGRESS: at 25.34% examples, 2114290 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:37,859 : INFO : EPOCH 18 - PROGRESS: at 51.17% examples, 2124238 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:38,862 : INFO : EPOCH 18 - PROGRESS: at 77.02% examples, 2133666 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:39,748 : INFO : EPOCH 18: training on 9696489 raw words (8351384 effective words) took 3.9s, 2141534 effective words/s\n",
      "2023-08-05 16:34:40,764 : INFO : EPOCH 19 - PROGRESS: at 25.24% examples, 2095970 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:41,769 : INFO : EPOCH 19 - PROGRESS: at 50.96% examples, 2114424 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:42,774 : INFO : EPOCH 19 - PROGRESS: at 76.61% examples, 2120297 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:43,703 : INFO : EPOCH 19: training on 9696489 raw words (8352672 effective words) took 3.9s, 2116644 effective words/s\n",
      "2023-08-05 16:34:44,719 : INFO : EPOCH 20 - PROGRESS: at 25.24% examples, 2095671 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:45,726 : INFO : EPOCH 20 - PROGRESS: at 50.02% examples, 2073674 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:46,727 : INFO : EPOCH 20 - PROGRESS: at 75.27% examples, 2084532 words/s, in_qsize 16, out_qsize 1\n",
      "2023-08-05 16:34:47,687 : INFO : EPOCH 20: training on 9696489 raw words (8351395 effective words) took 4.0s, 2100888 effective words/s\n",
      "2023-08-05 16:34:48,700 : INFO : EPOCH 21 - PROGRESS: at 24.93% examples, 2075832 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:49,704 : INFO : EPOCH 21 - PROGRESS: at 50.76% examples, 2111169 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:50,705 : INFO : EPOCH 21 - PROGRESS: at 76.30% examples, 2118508 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:51,629 : INFO : EPOCH 21: training on 9696489 raw words (8353058 effective words) took 3.9s, 2124138 effective words/s\n",
      "2023-08-05 16:34:52,648 : INFO : EPOCH 22 - PROGRESS: at 25.14% examples, 2093431 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:53,653 : INFO : EPOCH 22 - PROGRESS: at 50.75% examples, 2109889 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:54,654 : INFO : EPOCH 22 - PROGRESS: at 76.30% examples, 2117161 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:34:55,577 : INFO : EPOCH 22: training on 9696489 raw words (8352689 effective words) took 3.9s, 2123984 effective words/s\n",
      "2023-08-05 16:34:56,591 : INFO : EPOCH 23 - PROGRESS: at 24.93% examples, 2074970 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:57,594 : INFO : EPOCH 23 - PROGRESS: at 50.76% examples, 2110234 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:58,598 : INFO : EPOCH 23 - PROGRESS: at 76.40% examples, 2118346 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:34:59,517 : INFO : EPOCH 23: training on 9696489 raw words (8352461 effective words) took 3.9s, 2125123 effective words/s\n",
      "2023-08-05 16:35:00,527 : INFO : EPOCH 24 - PROGRESS: at 25.13% examples, 2098745 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:01,529 : INFO : EPOCH 24 - PROGRESS: at 50.96% examples, 2124082 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:02,533 : INFO : EPOCH 24 - PROGRESS: at 76.61% examples, 2127936 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:03,433 : INFO : EPOCH 24: training on 9696489 raw words (8353262 effective words) took 3.9s, 2138388 effective words/s\n",
      "2023-08-05 16:35:04,450 : INFO : EPOCH 25 - PROGRESS: at 25.24% examples, 2092653 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:05,453 : INFO : EPOCH 25 - PROGRESS: at 51.47% examples, 2136080 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:06,458 : INFO : EPOCH 25 - PROGRESS: at 77.33% examples, 2140531 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:07,330 : INFO : EPOCH 25: training on 9696489 raw words (8351517 effective words) took 3.9s, 2148174 effective words/s\n",
      "2023-08-05 16:35:08,343 : INFO : EPOCH 26 - PROGRESS: at 24.62% examples, 2049491 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:09,345 : INFO : EPOCH 26 - PROGRESS: at 49.82% examples, 2073730 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:10,348 : INFO : EPOCH 26 - PROGRESS: at 75.06% examples, 2083321 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:11,326 : INFO : EPOCH 26: training on 9696489 raw words (8352518 effective words) took 4.0s, 2095005 effective words/s\n",
      "2023-08-05 16:35:12,339 : INFO : EPOCH 27 - PROGRESS: at 25.24% examples, 2101542 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:13,342 : INFO : EPOCH 27 - PROGRESS: at 50.86% examples, 2115688 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:14,343 : INFO : EPOCH 27 - PROGRESS: at 76.51% examples, 2124101 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:15,273 : INFO : EPOCH 27: training on 9696489 raw words (8352654 effective words) took 3.9s, 2121421 effective words/s\n",
      "2023-08-05 16:35:16,286 : INFO : EPOCH 28 - PROGRESS: at 25.14% examples, 2092033 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:17,289 : INFO : EPOCH 28 - PROGRESS: at 50.96% examples, 2119421 words/s, in_qsize 16, out_qsize 1\n",
      "2023-08-05 16:35:18,293 : INFO : EPOCH 28 - PROGRESS: at 76.61% examples, 2124389 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:19,196 : INFO : EPOCH 28: training on 9696489 raw words (8352861 effective words) took 3.9s, 2134137 effective words/s\n",
      "2023-08-05 16:35:20,207 : INFO : EPOCH 29 - PROGRESS: at 25.24% examples, 2104718 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:21,214 : INFO : EPOCH 29 - PROGRESS: at 51.17% examples, 2126168 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:22,217 : INFO : EPOCH 29 - PROGRESS: at 76.81% examples, 2129507 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:23,106 : INFO : EPOCH 29: training on 9696489 raw words (8353112 effective words) took 3.9s, 2141390 effective words/s\n",
      "2023-08-05 16:35:24,119 : INFO : EPOCH 30 - PROGRESS: at 25.13% examples, 2092878 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:25,120 : INFO : EPOCH 30 - PROGRESS: at 50.65% examples, 2108134 words/s, in_qsize 16, out_qsize 1\n",
      "2023-08-05 16:35:26,140 : INFO : EPOCH 30 - PROGRESS: at 75.99% examples, 2097890 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:27,095 : INFO : EPOCH 30: training on 9696489 raw words (8352228 effective words) took 4.0s, 2098590 effective words/s\n",
      "2023-08-05 16:35:28,117 : INFO : EPOCH 31 - PROGRESS: at 24.83% examples, 2066180 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:29,118 : INFO : EPOCH 31 - PROGRESS: at 50.13% examples, 2087066 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:30,121 : INFO : EPOCH 31 - PROGRESS: at 75.68% examples, 2100704 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:31,058 : INFO : EPOCH 31: training on 9696489 raw words (8353347 effective words) took 3.9s, 2117219 effective words/s\n",
      "2023-08-05 16:35:32,069 : INFO : EPOCH 32 - PROGRESS: at 25.14% examples, 2097380 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:33,069 : INFO : EPOCH 32 - PROGRESS: at 50.75% examples, 2116432 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:34,073 : INFO : EPOCH 32 - PROGRESS: at 76.30% examples, 2120149 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:34,983 : INFO : EPOCH 32: training on 9696489 raw words (8352202 effective words) took 3.9s, 2133051 effective words/s\n",
      "2023-08-05 16:35:35,993 : INFO : EPOCH 33 - PROGRESS: at 24.93% examples, 2082585 words/s, in_qsize 16, out_qsize 0\n",
      "2023-08-05 16:35:36,997 : INFO : EPOCH 33 - PROGRESS: at 50.44% examples, 2100893 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:38,003 : INFO : EPOCH 33 - PROGRESS: at 75.37% examples, 2090668 words/s, in_qsize 15, out_qsize 0\n",
      "2023-08-05 16:35:38,976 : INFO : EPOCH 33: training on 9696489 raw words (8351714 effective words) took 4.0s, 2096840 effective words/s\n",
      "2023-08-05 16:35:39,987 : INFO : EPOCH 34 - PROGRESS: at 25.24% examples, 2105964 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:40,987 : INFO : EPOCH 34 - PROGRESS: at 50.65% examples, 2112681 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:41,987 : INFO : EPOCH 34 - PROGRESS: at 76.30% examples, 2122883 words/s, in_qsize 14, out_qsize 1\n",
      "2023-08-05 16:35:42,914 : INFO : EPOCH 34: training on 9696489 raw words (8353617 effective words) took 3.9s, 2126198 effective words/s\n",
      "2023-08-05 16:35:42,915 : INFO : Word2Vec lifecycle event {'msg': 'training on 339377115 raw words (292334327 effective words) took 138.3s, 2113401 effective words/s', 'datetime': '2023-08-05T16:35:42.915306', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 54s, sys: 3.47 s, total: 14min 57s\n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(292334327, 339377115)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word2vec.train(documents, total_examples=len(documents), epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:30:14.577242Z",
     "iopub.status.busy": "2023-07-28T23:30:14.576839Z",
     "iopub.status.idle": "2023-07-28T23:30:14.582149Z",
     "shell.execute_reply": "2023-07-28T23:30:14.581091Z",
     "shell.execute_reply.started": "2023-07-28T23:30:14.577201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get word embeddings from the trained model\n",
    "word_vectors = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:31:05.462652Z",
     "iopub.status.busy": "2023-07-28T23:31:05.462212Z",
     "iopub.status.idle": "2023-07-28T23:31:05.476784Z",
     "shell.execute_reply": "2023-07-28T23:31:05.475619Z",
     "shell.execute_reply.started": "2023-07-28T23:31:05.462618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('playing', 0.5671182870864868),\n",
       " ('play.', 0.5137702822685242),\n",
       " ('played', 0.448461651802063),\n",
       " ('watch', 0.41694873571395874),\n",
       " ('play,', 0.41017264127731323),\n",
       " ('play!', 0.4066566228866577),\n",
       " ('plays', 0.4031645953655243),\n",
       " ('riffs', 0.39981046319007874),\n",
       " ('playin', 0.3966851830482483),\n",
       " ('sing', 0.3930867910385132)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(\"play\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:33:05.279371Z",
     "iopub.status.busy": "2023-07-28T23:33:05.278270Z",
     "iopub.status.idle": "2023-07-28T23:33:05.439528Z",
     "shell.execute_reply": "2023-07-28T23:33:05.438200Z",
     "shell.execute_reply.started": "2023-07-28T23:33:05.279305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 16:41:28,896 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec_model.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-08-05T16:41:28.896541', 'gensim': '4.3.1', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.2.1-arm64-arm-64bit', 'event': 'saving'}\n",
      "2023-08-05 16:41:28,901 : INFO : storing np array 'vectors' to word2vec_model.bin.wv.vectors.npy\n",
      "2023-08-05 16:41:28,982 : INFO : storing np array 'syn1neg' to word2vec_model.bin.syn1neg.npy\n",
      "2023-08-05 16:41:29,058 : INFO : not storing attribute cum_table\n",
      "2023-08-05 16:41:29,165 : INFO : saved word2vec_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the Word2Vec model\n",
    "model_save_path = \"word2vec_model.bin\"\n",
    "\n",
    "# Save the Word2Vec model to the specified path\n",
    "word2vec.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:39:51.863921Z",
     "iopub.status.busy": "2023-07-28T23:39:51.863477Z",
     "iopub.status.idle": "2023-07-28T23:40:14.415025Z",
     "shell.execute_reply": "2023-07-28T23:40:14.413980Z",
     "shell.execute_reply.started": "2023-07-28T23:39:51.863884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 274664\n"
     ]
    }
   ],
   "source": [
    "# Create a Tokenizer object\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the Tokenizer on the text data from the training dataframe (df_train)\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "# Calculate the vocabulary size by adding 1 to the maximum index in the word index created by the Tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Print the total number of words in the vocabulary\n",
    "print(\"Total words\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:45:20.219535Z",
     "iopub.status.busy": "2023-07-28T23:45:20.218973Z",
     "iopub.status.idle": "2023-07-28T23:45:20.226041Z",
     "shell.execute_reply": "2023-07-28T23:45:20.224920Z",
     "shell.execute_reply.started": "2023-07-28T23:45:20.219486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the sequence length for input data\n",
    "SEQUENCE_LENGTH = 300\n",
    "\n",
    "# Set the number of epochs for training\n",
    "EPOCHS = 8\n",
    "\n",
    "# Specify the batch size for training\n",
    "BATCH_SIZE = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274663"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:45:23.036676Z",
     "iopub.status.busy": "2023-07-28T23:45:23.036273Z",
     "iopub.status.idle": "2023-07-28T23:45:51.968164Z",
     "shell.execute_reply": "2023-07-28T23:45:51.967072Z",
     "shell.execute_reply.started": "2023-07-28T23:45:23.036647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the text data in the 'df_train' DataFrame to sequences of tokens using the tokenizer\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train.text)\n",
    "\n",
    "# Pad the sequences to ensure they all have the same length of 'SEQUENCE_LENGTH'\n",
    "x_train = pad_sequences(train_sequences, maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "# Convert the text data in the 'df_test' DataFrame to sequences of tokens using the tokenizer\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test.text)\n",
    "\n",
    "# Pad the sequences to ensure they all have the same length of 'SEQUENCE_LENGTH'\n",
    "x_test = pad_sequences(test_sequences, maxlen=SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:46:42.789130Z",
     "iopub.status.busy": "2023-07-28T23:46:42.788033Z",
     "iopub.status.idle": "2023-07-28T23:46:42.793567Z",
     "shell.execute_reply": "2023-07-28T23:46:42.792422Z",
     "shell.execute_reply.started": "2023-07-28T23:46:42.789088Z"
    }
   },
   "outputs": [],
   "source": [
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"  # Represents a positive sentiment\n",
    "NEGATIVE = \"NEGATIVE\"  # Represents a negative sentiment\n",
    "NEUTRAL = \"NEUTRAL\"    # Represents a neutral sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:45:56.763463Z",
     "iopub.status.busy": "2023-07-28T23:45:56.762243Z",
     "iopub.status.idle": "2023-07-28T23:45:56.857961Z",
     "shell.execute_reply": "2023-07-28T23:45:56.856996Z",
     "shell.execute_reply.started": "2023-07-28T23:45:56.763420Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = df_train.target.unique().tolist()  # Get unique target values and convert to a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:46:51.650070Z",
     "iopub.status.busy": "2023-07-28T23:46:51.649635Z",
     "iopub.status.idle": "2023-07-28T23:46:51.655477Z",
     "shell.execute_reply": "2023-07-28T23:46:51.654392Z",
     "shell.execute_reply.started": "2023-07-28T23:46:51.650036Z"
    }
   },
   "outputs": [],
   "source": [
    "labels.append(NEUTRAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:46:57.148597Z",
     "iopub.status.busy": "2023-07-28T23:46:57.148223Z",
     "iopub.status.idle": "2023-07-28T23:46:57.154024Z",
     "shell.execute_reply": "2023-07-28T23:46:57.153255Z",
     "shell.execute_reply.started": "2023-07-28T23:46:57.148569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['postive', 'Negative', 'NEUTRAL']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:49:26.899322Z",
     "iopub.status.busy": "2023-07-28T23:49:26.898199Z",
     "iopub.status.idle": "2023-07-28T23:49:26.903737Z",
     "shell.execute_reply": "2023-07-28T23:49:26.902701Z",
     "shell.execute_reply.started": "2023-07-28T23:49:26.899282Z"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:49:49.333601Z",
     "iopub.status.busy": "2023-07-28T23:49:49.333213Z",
     "iopub.status.idle": "2023-07-28T23:49:49.338378Z",
     "shell.execute_reply": "2023-07-28T23:49:49.337294Z",
     "shell.execute_reply.started": "2023-07-28T23:49:49.333571Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical labels into Numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:49:52.545879Z",
     "iopub.status.busy": "2023-07-28T23:49:52.545265Z",
     "iopub.status.idle": "2023-07-28T23:49:53.130472Z",
     "shell.execute_reply": "2023-07-28T23:49:53.129511Z",
     "shell.execute_reply.started": "2023-07-28T23:49:52.545848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the LabelEncoder class\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'target' column data in the df_train DataFrame\n",
    "encoder.fit(df_train.target.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:50:56.190789Z",
     "iopub.status.busy": "2023-07-28T23:50:56.190245Z",
     "iopub.status.idle": "2023-07-28T23:50:57.178955Z",
     "shell.execute_reply": "2023-07-28T23:50:57.178053Z",
     "shell.execute_reply.started": "2023-07-28T23:50:56.190743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the target values in the df_train dataframe using the encoder\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "\n",
    "# Transform the target values in the df_test dataframe using the encoder\n",
    "y_test = encoder.transform(df_test.target.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:51:44.927390Z",
     "iopub.status.busy": "2023-07-28T23:51:44.926927Z",
     "iopub.status.idle": "2023-07-28T23:51:44.933617Z",
     "shell.execute_reply": "2023-07-28T23:51:44.932362Z",
     "shell.execute_reply.started": "2023-07-28T23:51:44.927352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (1280000, 1)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_train to have a single column\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "# Reshape y_test to have a single column\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Print the shape of the reshaped y_train array\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "# Print the shape of the reshaped y_test array\n",
    "print(\"y_test\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T23:51:59.213139Z",
     "iopub.status.busy": "2023-07-28T23:51:59.212745Z",
     "iopub.status.idle": "2023-07-28T23:51:59.219051Z",
     "shell.execute_reply": "2023-07-28T23:51:59.218218Z",
     "shell.execute_reply.started": "2023-07-28T23:51:59.213105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (1280000, 300)\n",
      "y_train (1280000, 1)\n",
      "\n",
      "x_test (320000, 300)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the training data features (x_train)\n",
    "print(\"x_train\", x_train.shape)\n",
    "\n",
    "# Printing the shape of the training data labels (y_train)\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "# Adding a blank line for separation\n",
    "print()\n",
    "\n",
    "# Printing the shape of the testing data features (x_test)\n",
    "print(\"x_test\", x_test.shape)\n",
    "\n",
    "# Printing the shape of the testing data labels (y_test)\n",
    "print(\"y_test\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:01:11.968787Z",
     "iopub.status.busy": "2023-07-29T00:01:11.968383Z",
     "iopub.status.idle": "2023-07-29T00:01:11.974295Z",
     "shell.execute_reply": "2023-07-29T00:01:11.972803Z",
     "shell.execute_reply.started": "2023-07-29T00:01:11.968753Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_size=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:02:56.710365Z",
     "iopub.status.busy": "2023-07-29T00:02:56.709972Z",
     "iopub.status.idle": "2023-07-29T00:02:56.715849Z",
     "shell.execute_reply": "2023-07-29T00:02:56.714680Z",
     "shell.execute_reply.started": "2023-07-29T00:02:56.710311Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:01:14.088105Z",
     "iopub.status.busy": "2023-07-29T00:01:14.087727Z",
     "iopub.status.idle": "2023-07-29T00:01:14.092952Z",
     "shell.execute_reply": "2023-07-29T00:01:14.091663Z",
     "shell.execute_reply.started": "2023-07-29T00:01:14.088075Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, vector_size))  # Initialize an embedding matrix with zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:01:29.743950Z",
     "iopub.status.busy": "2023-07-29T00:01:29.743558Z",
     "iopub.status.idle": "2023-07-29T00:01:30.135227Z",
     "shell.execute_reply": "2023-07-29T00:01:30.134418Z",
     "shell.execute_reply.started": "2023-07-29T00:01:29.743917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274664, 300)\n"
     ]
    }
   ],
   "source": [
    "for word, i in tokenizer.word_index.items():  # Iterate through word indices from the tokenizer\n",
    "    if word in word2vec.wv:  # Check if the word is present in the word2vec vocabulary\n",
    "        embedding_matrix[i] = word2vec.wv[word]  # Assign the word's embedding to the corresponding index in the matrix\n",
    "# Print the shape of the embedding matrix\n",
    "print(embedding_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:02:58.818470Z",
     "iopub.status.busy": "2023-07-29T00:02:58.818028Z",
     "iopub.status.idle": "2023-07-29T00:02:58.848449Z",
     "shell.execute_reply": "2023-07-29T00:02:58.847283Z",
     "shell.execute_reply.started": "2023-07-29T00:02:58.818433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an embedding layer with specific parameters\n",
    "embedding_layer = Embedding(vocab_size, vector_size, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch  # Import the PyTorch library\n",
    "\n",
    "# Check if the MPS (Memory Pooling and Sharing) backend is available\n",
    "if torch.backends.mps.is_available():  # Check if MPS is available\n",
    "    mps_device = torch.device(\"mps\")  # Create an MPS device object\n",
    "    x = torch.ones(1, device=mps_device)  # Create a tensor of ones on the MPS device\n",
    "    print(x)  # Print the tensor\n",
    "else:\n",
    "    print(\"MPS device not found.\")  # Print a message if MPS is not available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 300)          82399200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300, 300)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               160400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82559701 (314.94 MB)\n",
      "Trainable params: 160501 (626.96 KB)\n",
      "Non-trainable params: 82399200 (314.33 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model instance\n",
    "model = Sequential()\n",
    "\n",
    "# Add the embedding layer to the model\n",
    "model.add(embedding_layer)\n",
    "\n",
    "# Add a Dropout layer with a dropout rate of 0.5\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add an LSTM layer with 100 units, using dropout and recurrent dropout of 0.2\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "# Add a Dense layer with 1 neuron and sigmoid activation function\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Display a summary of the model's architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:04:19.324282Z",
     "iopub.status.busy": "2023-07-29T00:04:19.323907Z",
     "iopub.status.idle": "2023-07-29T00:04:19.345539Z",
     "shell.execute_reply": "2023-07-29T00:04:19.344323Z",
     "shell.execute_reply.started": "2023-07-29T00:04:19.324253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compiles the model with binary cross-entropy loss, Adam optimizer, and accuracy metric\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:04:53.756120Z",
     "iopub.status.busy": "2023-07-29T00:04:53.755131Z",
     "iopub.status.idle": "2023-07-29T00:04:53.762214Z",
     "shell.execute_reply": "2023-07-29T00:04:53.761009Z",
     "shell.execute_reply.started": "2023-07-29T00:04:53.756082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary callback classes\n",
    "callbacks = [\n",
    "    # Reduce learning rate when validation loss plateaus\n",
    "    ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "    \n",
    "    # Stop training early if validation accuracy improvement is small for a certain number of epochs\n",
    "    EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:05:06.997265Z",
     "iopub.status.busy": "2023-07-29T00:05:06.996818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.7514WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 17:36:12,702 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3256s 3s/step - loss: 0.5027 - accuracy: 0.7514 - val_loss: 0.4683 - val_accuracy: 0.7792 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.7699WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 18:30:59,770 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3287s 3s/step - loss: 0.4757 - accuracy: 0.7699 - val_loss: 0.4577 - val_accuracy: 0.7850 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.7743WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 19:27:03,987 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3364s 3s/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4527 - val_accuracy: 0.7873 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4646 - accuracy: 0.7763WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 20:23:31,038 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3387s 3s/step - loss: 0.4646 - accuracy: 0.7763 - val_loss: 0.4498 - val_accuracy: 0.7889 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.7784WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 21:19:05,546 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3335s 3s/step - loss: 0.4616 - accuracy: 0.7784 - val_loss: 0.4491 - val_accuracy: 0.7893 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.7796WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 22:14:31,844 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3326s 3s/step - loss: 0.4596 - accuracy: 0.7796 - val_loss: 0.4478 - val_accuracy: 0.7903 - lr: 0.0010\n",
      "Epoch 7/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.7805WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 23:10:15,463 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3344s 3s/step - loss: 0.4583 - accuracy: 0.7805 - val_loss: 0.4456 - val_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 8/8\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.7814WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 00:06:44,237 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 3389s 3s/step - loss: 0.4570 - accuracy: 0.7814 - val_loss: 0.4458 - val_accuracy: 0.7921 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Training the model using the fit() function\n",
    "history = model.fit(\n",
    "    x_train,             # Input training data\n",
    "    y_train,             # Target training data\n",
    "    batch_size=BATCH_SIZE,  # Number of samples in each update\n",
    "    epochs=EPOCHS,          # Number of times to iterate over the entire training dataset\n",
    "    validation_split=0.1,   # Fraction of training data to use for validation\n",
    "    verbose=1,              # Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
    "    callbacks=callbacks    # List of callbacks to apply during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/sayedraheel/Desktop/NLP/Twitter_sent/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 00:57:39,352 : INFO : Assets written to: /Users/sayedraheel/Desktop/NLP/Twitter_sent/assets\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where the model will be saved\n",
    "save_directory = \"/Users/sayedraheel/Desktop/NLP/Twitter_sent\"\n",
    "\n",
    "# Save the model\n",
    "model.save(save_directory)\n",
    "\n",
    "# This code defines the directory where the model will be saved\n",
    "# and then saves the model in that specified directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.save of <keras.src.engine.sequential.Sequential object at 0x2f7bb59c0>>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 214s 683ms/step - loss: 0.4422 - accuracy: 0.7933\n",
      "\n",
      "ACCURACY: 0.7933375239372253\n",
      "LOSS: 0.44216927886009216\n",
      "CPU times: user 11min 9s, sys: 3min 38s, total: 14min 47s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:\n",
    "        # If the score is less than or equal to the lowest threshold, classify as NEGATIVE\n",
    "        label = NEUTRAL  # Note: NEUTRAL, NEGATIVE, and POSITIVE should be defined somewhere in the code\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        # If the score is greater than or equal to the highest threshold, classify as POSITIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label  # Return the determined sentiment label\n",
    "    else:\n",
    "        # If include_neutral is set to False, classify as NEGATIVE if the score is less than 0.5, otherwise POSITIVE\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the custom path to save the word_index to a JSON file\n",
    "custom_path = '/Users/sayedraheel/Desktop/NLP/tokenizer_word_index.json'\n",
    "\n",
    "# Save the word_index to the specified JSON file path\n",
    "with open(custom_path, 'w') as json_file:\n",
    "    json.dump(tokenizer.word_index, json_file)  # Save the word_index using the JSON format to the specified file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()  # Record the starting time\n",
    "    \n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    \n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    \n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "    \n",
    "    # Return prediction results along with elapsed time\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"score\": float(score),\n",
    "        \"elapsed_time\": time.time() - start_at\n",
    "    }, x_test  # Also return the preprocessed input sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'label': 'POSITIVE',\n",
       "  'score': 0.9330912828445435,\n",
       "  'elapsed_time': 0.07188105583190918},\n",
       " array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0, 65, 11, 36]], dtype=int32))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'NEGATIVE',\n",
       " 'score': 0.054390810430049896,\n",
       " 'elapsed_time': 0.06615281105041504}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'NEUTRAL',\n",
       " 'score': 0.5441814661026001,\n",
       " 'elapsed_time': 0.06898093223571777}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('i have told you my address you should be able to come now ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'POSITIVE',\n",
       " 'score': 0.8510990738868713,\n",
       " 'elapsed_time': 0.06298017501831055}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('the movie  not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sayedraheel/Desktop/NLP/Sentiment/Sentiment model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the Keras model to the specified file path\n",
    "model.save('/Users/sayedraheel/Desktop/NLP/Sentiment/Sentiment model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/code/paoloripamonti/twitter-sentiment-analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
